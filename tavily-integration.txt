
https://community.vercel.com/t/how-do-i-connect-tavily-mcp-with-vercel-ai-sdk/20947
How do I connect Tavily MCP with Vercel AI SDK?
AI SDK

Mxhiraz
30d
How to connect Tavily (https://www.tavily.com) MCP with the Vercel AI SDK



56
views

4
links



Unlisted on Aug 28


Listed on Aug 28


Amy Egan 
Vercel Staff
30d
Asked v0 for the answer, and here’s what it gave me:

You can connect Tavily’s MCP (Model Context Protocol) server with the Vercel AI SDK using the new MCP client support introduced in AI SDK 4.2.

Here’s how to set it up:

Using Tavily’s Remote MCP Server
The easiest way is to use Tavily’s remote MCP server directly:

import { createMCPClient } from '@ai-sdk/mcp'

const mcpClient = createMCPClient({
  name: 'tavily',
  version: '1.0.0',
  transport: {
    type: 'http',
    url: 'https://mcp.tavily.com/mcp/?tavilyApiKey=YOUR_TAVILY_API_KEY'
  }
})
Using with AI SDK Functions
Once connected, you can use Tavily’s search tools in your AI SDK functions:

import { generateText } from 'ai'
import { openai } from '@ai-sdk/openai'

const { text } = await generateText({
  model: openai('gpt-4'),
  prompt: 'Search for the latest news about AI developments',
  tools: await mcpClient.getTools(), // This includes tavily-search, tavily-extract, etc.
})
Available Tavily Tools
The Tavily MCP server provides several tools:

tavily-search: Real-time web search
tavily-extract: Intelligent data extraction from web pages
tavily-map: Creates structured maps of websites
tavily-crawl: Systematically explores websites
Make sure to get your Tavily API key from tavily.com and replace YOUR_TAVILY_API_KEY in the URL.

Resources:

AI SDK MCP Documentation
Tavily MCP GitHub Repository
I hope that helps!

_________________________________________________________________________________________________________________________________________________________
https://ai-sdk.dev/docs/reference/ai-sdk-core/create-mcp-client
AI SDK Core
experimental_createMCPClient
experimental_createMCPClient()
Creates a lightweight Model Context Protocol (MCP) client that connects to an MCP server. The client's primary purpose is tool conversion between MCP tools and AI SDK tools.

It currently does not support accepting notifications from an MCP server, and custom configuration of the client.

This feature is experimental and may change or be removed in the future.

Import
import { experimental_createMCPClient } from "ai"
API Signature
Parameters
config:
MCPClientConfig
Configuration for the MCP client.
MCPClientConfig
transport:
TransportConfig = MCPTransport | McpSSEServerConfig
Configuration for the message transport layer.
MCPTransport
start:
() => Promise<void>
A method that starts the transport
send:
(message: JSONRPCMessage) => Promise<void>
A method that sends a message through the transport
close:
() => Promise<void>
A method that closes the transport
onclose:
() => void
A method that is called when the transport is closed
onerror:
(error: Error) => void
A method that is called when the transport encounters an error
onmessage:
(message: JSONRPCMessage) => void
A method that is called when the transport receives a message
McpSSEServerConfig
type:
'sse'
Use Server-Sent Events for communication
url:
string
URL of the MCP server
headers?:
Record<string, string>
Additional HTTP headers to be sent with requests.
name?:
string
Client name. Defaults to "ai-sdk-mcp-client"
onUncaughtError?:
(error: unknown) => void
Handler for uncaught errors
Returns
Returns a Promise that resolves to an MCPClient with the following methods:

tools:
async (options?: { schemas?: TOOL_SCHEMAS }) => Promise<McpToolSet<TOOL_SCHEMAS>>
Gets the tools available from the MCP server.
options
schemas?:
TOOL_SCHEMAS
Schema definitions for compile-time type checking. When not provided, schemas are inferred from the server.
close:
async () => void
Closes the connection to the MCP server and cleans up resources.
Example

import { experimental_createMCPClient, generateText } from 'ai';
import { Experimental_StdioMCPTransport } from 'ai/mcp-stdio';
import { openai } from '@ai-sdk/openai';

let client;

try {
  client = await experimental_createMCPClient({
    transport: new Experimental_StdioMCPTransport({
      command: 'node server.js',
    }),
  });

  const tools = await client.tools();

  const response = await generateText({
    model: openai('gpt-4o-mini'),
    tools,
    messages: [{ role: 'user', content: 'Query the data' }],
  });

  console.log(response);
} catch (error) {
  console.error('Error:', error);
} finally {
  // ensure the client is closed even if an error occurs
  if (client) {
    await client.close();
  }
}
Error Handling
The client throws MCPClientError for:

Client initialization failures
Protocol version mismatches
Missing server capabilities
Connection failures
For tool execution, errors are propagated as CallToolError errors.

For unknown errors, the client exposes an onUncaughtError callback that can be used to manually log or handle errors that are not covered by known error types.
_________________________________________________________________________________________________________________________________________________________
https://ai-sdk.dev/docs/ai-sdk-core/mcp-tools
AI SDK Core
Model Context Protocol (MCP) Tools
Model Context Protocol (MCP) Tools
The MCP tools feature is experimental and may change in the future.

The AI SDK supports connecting to Model Context Protocol (MCP) servers to access their tools. This enables your AI applications to discover and use tools across various services through a standardized interface.

Initializing an MCP Client
We recommend using HTTP transport (like StreamableHTTPClientTransport) for production deployments. The stdio transport should only be used for connecting to local servers as it cannot be deployed to production environments.

Create an MCP client using one of the following transport options:

HTTP transport (Recommended): Use transports from MCP's official TypeScript SDK like StreamableHTTPClientTransport for production deployments
SSE (Server-Sent Events): An alternative HTTP-based transport
stdio: For local development only. Uses standard input/output streams for local MCP servers
HTTP Transport (Recommended)
For production deployments, we recommend using HTTP transports like StreamableHTTPClientTransport from MCP's official TypeScript SDK:


import { experimental_createMCPClient as createMCPClient } from 'ai';
import { StreamableHTTPClientTransport } from '@modelcontextprotocol/sdk/client/streamableHttp.js';

const url = new URL('https://your-server.com/mcp');
const mcpClient = await createMCPClient({
  transport: new StreamableHTTPClientTransport(url, {
    sessionId: 'session_123',
  }),
});
SSE Transport
SSE provides an alternative HTTP-based transport option. Configure it with a type and url property:


import { experimental_createMCPClient as createMCPClient } from 'ai';

const mcpClient = await createMCPClient({
  transport: {
    type: 'sse',
    url: 'https://my-server.com/sse',

    // optional: configure HTTP headers, e.g. for authentication
    headers: {
      Authorization: 'Bearer my-api-key',
    },
  },
});
Stdio Transport (Local Servers)
The stdio transport should only be used for local servers.

The Stdio transport can be imported from either the MCP SDK or the AI SDK:


import { experimental_createMCPClient as createMCPClient } from 'ai';
import { StdioClientTransport } from '@modelcontextprotocol/sdk/client/stdio.js';
// Or use the AI SDK's stdio transport:
// import { Experimental_StdioMCPTransport as StdioClientTransport } from 'ai/mcp-stdio';

const mcpClient = await createMCPClient({
  transport: new StdioClientTransport({
    command: 'node',
    args: ['src/stdio/dist/server.js'],
  }),
});
Custom Transport
You can also bring your own transport by implementing the MCPTransport interface for specific requirements not covered by the standard transports.

The client returned by the experimental_createMCPClient function is a lightweight client intended for use in tool conversion. It currently does not support all features of the full MCP client, such as: authorization, session management, resumable streams, and receiving notifications.

Closing the MCP Client
After initialization, you should close the MCP client based on your usage pattern:

For short-lived usage (e.g., single requests), close the client when the response is finished
For long-running clients (e.g., command line apps), keep the client open but ensure it's closed when the application terminates
When streaming responses, you can close the client when the LLM response has finished. For example, when using streamText, you should use the onFinish callback:


const mcpClient = await experimental_createMCPClient({
  // ...
});

const tools = await mcpClient.tools();

const result = await streamText({
  model: 'openai/gpt-4.1',
  tools,
  prompt: 'What is the weather in Brooklyn, New York?',
  onFinish: async () => {
    await mcpClient.close();
  },
});
When generating responses without streaming, you can use try/finally or cleanup functions in your framework:


let mcpClient: MCPClient | undefined;

try {
  mcpClient = await experimental_createMCPClient({
    // ...
  });
} finally {
  await mcpClient?.close();
}
Using MCP Tools
The client's tools method acts as an adapter between MCP tools and AI SDK tools. It supports two approaches for working with tool schemas:

Schema Discovery
With schema discovery, all tools offered by the server are automatically listed, and input parameter types are inferred based on the schemas provided by the server:


const tools = await mcpClient.tools();
This approach is simpler to implement and automatically stays in sync with server changes. However, you won't have TypeScript type safety during development, and all tools from the server will be loaded

Schema Definition
For better type safety and control, you can define the tools and their input schemas explicitly in your client code:


import { z } from 'zod';

const tools = await mcpClient.tools({
  schemas: {
    'get-data': {
      inputSchema: z.object({
        query: z.string().describe('The data query'),
        format: z.enum(['json', 'text']).optional(),
      }),
    },
    // For tools with zero inputs, you should use an empty object:
    'tool-with-no-args': {
      inputSchema: z.object({}),
    },
  },
});
This approach provides full TypeScript type safety and IDE autocompletion, letting you catch parameter mismatches during development. When you define schemas, the client only pulls the explicitly defined tools, keeping your application focused on the tools it needs

_________________________________________________________________________________________________________________________________________________________
JavaScript
SDK Reference
Integrate Tavily’s powerful APIs natively in your JavaScript/TypeScript projects.

​
Instantiating a client
To interact with Tavily in JavaScript, you must instatiate a client with your API key. Our client is asynchronous by default.
Once you have instantiated a client, call one of our supported methods (detailed below) to access the API.

Copy

Ask AI
const { tavily } = require("@tavily/core");

client = tavily({ apiKey: "tvly-YOUR_API_KEY" });
​
Proxies
If you would like to specify a proxy to be used when making requests, you can do so by passing in a proxy parameter on client instantiation.
Proxy configuration is available in both the synchronous and asynchronous clients.

Copy

Ask AI
const { tavily } = require("@tavily/core");

const proxies = {
  http: "<your HTTP proxy>",
  https: "<your HTTPS proxy>",
};

client = tavily({ apiKey: "tvly-YOUR_API_KEY", proxies });
Alternatively, you can specify which proxies to use by setting the TAVILY_HTTP_PROXY and TAVILY_HTTPS_PROXY variables in your environment file.
​
Tavily Search
NEW! Try our interactive API Playground to see each parameter in action, and generate ready-to-use JavaScript snippets.
You can access Tavily Search in JavaScript through the client’s search function.
​
Parameters
Parameter	Type	Description	Default
query (required)	string	The query to run a search on.	—
auto_parameters	boolean	When auto_parameters is enabled, Tavily automatically configures search parameters based on your query’s content and intent. You can still set other parameters manually, and your explicit values will override the automatic ones. The parameters include_answer, include_raw_content, and max_results must always be set manually, as they directly affect response size. Note: search_depth may be automatically set to advanced when it’s likely to improve results. This uses 2 API credits per request. To avoid the extra cost, you can explicitly set search_depth to basic.	false
searchDepth	string	The depth of the search. It can be "basic" or "advanced". "advanced" search is tailored to retrieve the most relevant sources and content snippets for your query, while "basic" search provides generic content snippets from each source.	"basic"
topic	string	The category of the search. Determines which agent will be used. Supported values are "general" , "news" and "finance".	"general"
days	number	The number of days back from the current date to include in the results ( publish date ). Available only when using the "news" topic.	7
timeRange	string	The time range back from the current date ( publish date ). Accepted values include "day", "week", "month", "year" or shorthand values "d", "w", "m", "y".	—
startDate	string	Will return all results after the specified start date ( publish date ). Required to be written in the format YYYY-MM-DD	—
endDate	string	Will return all results before the specified end date ( publish date ). Required to be written in the format YYYY-MM-DD.	—
maxResults	number	The maximum number of search results to return. It must be between 0 and 20.	5
chunksPerSource	number	Chunks are short content snippets (maximum 500 characters each) pulled directly from the source. Use chunksPerSource to define the maximum number of relevant chunks returned per source and to control the content length. Chunks will appear in the content field as: <chunk 1> [...] <chunk 2> [...] <chunk 3>. Available only when searchDepth is "advanced".	3
includeImages	boolean	Include a list of query-related images in the response.	false
includeImageDescriptions	boolean	Include a list of query-related images and their descriptions in the response.	false
includeAnswer	boolean or string	Include an answer to the query generated by an LLM based on search results. A "basic" (or true) answer is quick but less detailed; an "advanced" answer is more detailed.	false
includeRawContent	boolean or string	Include the cleaned and parsed HTML content of each search result. "markdown" or True returns search result content in markdown format. "text" returns the plain text from the results and may increase latency.	False
includeDomains	string[]	A list of domains to specifically include in the search results. Maximum 300 domains.	[]
excludeDomains	string[]	A list of domains to specifically exclude from the search results. Maximum 150 domains.	[]
country	string	Boost search results from a specific country. This will prioritize content from the selected country in the search results. Available only if topic is general.	—
timeout	number	A timeout to be used in requests to the Tavily API.	60
includeFavicon	boolean	Whether to include the favicon URL for each result.	false
​
Response format
The response object you receive will be in the following format:
Key	Type	Description
results	Result[]	A list of sorted search results ranked by relevancy.
query	string	Your search query.
responseTime	number	Your search result response time.
requestId	string	A unique request identifier you can share with customer support to help resolve issues with specific requests.
answer (optional)	string	The answer to your search query, generated by an LLM based on Tavily’s search results. This is only available if includeAnswer is set to true.
images (optional)	string[] or ImageResult[]	This is only available if includeImages is set to true. A list of query-related image URLs. If includeImageDescriptions is set to true, each entry will be an ImageResult.
favicon (optional)	string	The favicon URL for the search result.
​
Results
Each result in the results list will be in the following Result format:
Key	Type	Description
title	string	The title of the search result.
url	string	The URL of the search result.
content	string	The most query-related content from the scraped URL. Tavily uses proprietary AI to extract the most relevant content based on context quality and size.
score	float	The relevance score of the search result.
rawContent (optional)	string	The parsed and cleaned HTML content of the site. This is only available if includeRawContent is set to true.
publishedDate (optional)	string	The publication date of the source. This is only available if the search topic is set to news.
favicon (optional)	string	”The favicon URL for the result.
​
Image Results
Each image in the images list will be in the following ImageResult format:
Key	Type	Description
url	string	The URL of the image.
description (optional)	string	This is only available if includeImageDescriptions is set to true. An LLM-generated description of the image.
​
Example
Request

Response

​
Tavily Extract
You can access Tavily Extract in JavaScript through the client’s extract function.
​
Parameters
Parameter	Type	Description	Default
urls (required)	string[]	The URLs you want to extract. The list must not contain more than 20 URLs.	—
includeImages	boolean	Include a list of images extracted from the URLs in the response.	false
extractDepth	string	The depth of the extraction process. You may experience higher latency with "advanced" extraction, but it offers a higher success rate and retrieves more data from the URL (e.g., tables, embedded content). "basic" extraction costs 1 API Credit per 5 successful URL extractions, while "advanced" extraction costs 2 API Credits per 5 successful URL extractions.	"basic"
format	str	The format of the extracted web page content. "markdown" returns content in markdown format. "text" returns plain text and may increase latency.	"markdown"
timeout	number	A timeout to be used in requests to the Tavily API. Maximum time in seconds to wait for the URL extraction before timing out. Must be between 1.0 and 60.0 seconds. If not specified, default timeouts are applied based on extract_depth: 10 seconds for basic extraction and 30 seconds for advanced extraction.	None
includeFavicon	boolean	Whether to include the favicon URL for each result.	false
​
Response format
The response object you receive will be in the following format:
Key	Type	Description
results	SuccessfulResult[]	A list of extracted content.
failed_results	FailedResult[]	A list of URLs that could not be processed.
response_time	number	The search result response time.
requestId	string	A unique request identifier you can share with customer support to help resolve issues with specific requests.
​
Successful Results
Each successful result in the results list will be in the following SuccessfulResult format:
Key	Type	Description
url	string	The URL of the webpage.
raw_content	string	The raw content extracted.
images (optional)	string[]	This is only available if includeImages is set to true. A list of extracted image URLs.
favicon (optional)	string	The favicon URL for the result.
​
Failed Results
Each failed result in the results list will be in the following FailedResult format:
Key	Type	Description
url	string	The URL that failed.
error	string	An error message describing why it could not be processed.
​
Example
Request

Response

​
Tavily Crawl
Our agent-first crawl endpoint is currently in open beta. Please repost any issues you encounter on our community page.
You can access Tavily Crawl in JavaScript through the client’s crawl function.
​
Parameters
Parameter	Type	Description	Default
url (required)	string	The root URL to begin the crawl.	—
maxDepth	number	Max depth of the crawl. Defines how far from the base URL the crawler can explore.	1
maxBreadth	number	Max number of links to follow per level of the tree (i.e., per page).	20
limit	number	Total number of links the crawler will process before stopping.	50
instructions	string	Natural language instructions for the crawler.	—
selectPaths	string[]	Regex patterns to select only URLs with specific path patterns (e.g., "/docs/.*", "/api/v1.*").	[]
selectDomains	string[]	Regex patterns to select crawling to specific domains or subdomains (e.g., "^docs\.example\.com$").	[]
excludePaths	string[]	Regex patterns to exclude URLs with specific path patterns (e.g., "/admin/.*", "/private/.*").	[]
excludeDomains	string[]	Regex patterns to exclude specific domains or subdomains from crawling (e.g., "^admin\.example\.com$").	[]
allowExternal	boolean	Whether to return links from external domains in crawl output.	true
includeImages	boolean	Whether to extract image URLs from the crawled pages.	false
extractDepth	string	Advanced extraction retrieves more data, including tables and embedded content, with higher success but may increase latency. Options: "basic" or "advanced".	"basic"
format	str	The format of the extracted web page content. "markdown" returns content in markdown format. "text" returns plain text and may increase latency.	"markdown"
timeout	number	A timeout to be used in requests to the Tavily API.	60
includeFavicon	boolean	Whether to include the favicon URL for each result.	false
​
Response format
The response object you receive will be in the following format:
Key	Type	Description
baseUrl	string	The URL you started the crawl from.
results	Result[]	A list of crawled pages.
responseTime	number	The crawl response time.
requestId	string	A unique request identifier you can share with customer support to help resolve issues with specific requests.
​
Results
Each successful result in the results list will be in the following Result format:
Key	Type	Description
url	string	The URL of the webpage.
rawContent	string	The raw content extracted.
images	string[]	Image URLs extracted from the page.
favicon (optional)	string	The favicon URL for the result.
​
Example
Request

Response

​
Tavily Map
Our agent-first mapping endpoint is currently in open beta. Please repost any issues you encounter on our community page.
You can access Tavily Map in JavaScript through the client’s map function.
​
Parameters
Parameter	Type	Description	Default
url (required)	string	The root URL to begin the mapping.	—
maxDepth	number	Max depth of the mapping. Defines how far from the base URL the crawler can explore.	1
maxBreadth	number	Max number of links to follow per level of the tree (i.e., per page).	20
limit	number	Total number of links the crawler will process before stopping.	50
instructions	string	Natural language instructions for the mapper.	—
selectPaths	string[]	Regex patterns to select only URLs with specific path patterns (e.g., "/docs/.*", "/api/v1.*").	[]
selectDomains	string[]	Regex patterns to select crawling to specific domains or subdomains (e.g., "^docs\.example\.com$").	[]
excludePaths	string[]	Regex patterns to exclude URLs with specific path patterns (e.g., "/admin/.*", "/private/.*").	[]
excludeDomains	string[]	Regex patterns to exclude specific domains or subdomains from mapping (e.g., "^admin\.example\.com$").	[]
allowExternal	boolean	Whether to return links from external domains in crawl output.	true
timeout	number	A timeout to be used in requests to the Tavily API.	60
​
Response format
The response object you receive will be in the following format:
Key	Type	Description
baseUrl	string	The URL you started the crawl from.
results	string[]	A list of URLs that were discovered during the mapping.
responseTime	number	The crawl response time.
requestId	string	A unique request identifier you can share with customer support to help resolve issues with specific requests.